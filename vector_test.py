# import numpy as np
# from openai import OpenAI
# import streamlit as st # æˆ‘ä»¬å€Ÿç”¨ streamlit çš„ secrets åŠŸèƒ½æ¥æ‹¿ Keyï¼Œæˆ–è€…ä½ ç›´æ¥å¡«ä¹Ÿè¡Œ

# # --- 1. é…ç½® API ---
# # âš ï¸ æ³¨æ„ï¼šEmbedding éœ€è¦ä¸“é—¨çš„æ¨¡å‹ï¼
# # å¦‚æœä½ ç”¨çš„æ˜¯ DeepSeek å®˜æ–¹ï¼Œæ¨¡å‹åé€šå¸¸å« "deepseek-embed"
# # å¦‚æœä½ ç”¨çš„æ˜¯ ç¡…åŸºæµåŠ¨(SiliconFlow)ï¼Œå¯èƒ½æ˜¯ "BAAI/bge-m3" æˆ– "text-embedding-3-small" (çœ‹å¹³å°æ”¯æŒ)
# # å¦‚æœä½ ä¸çŸ¥é“ç”¨å•¥ï¼Œå…ˆè¯•ç€å¡« "text-embedding-3-small" (è¿™æ˜¯ OpenAI æ ‡å‡†åï¼Œå¾ˆå¤šä¸­è½¬å•†å…¼å®¹)
# EMBEDDING_MODEL = "BAAI/bge-m3" 

# # è¿™é‡Œå¡«ä½ çš„é…ç½®ï¼Œæˆ–è€…ä» web_app.py æŠ„è¿‡æ¥
# client = OpenAI(
#     api_key="sk-xiewteiwyqvqsaxehcttthserqjbkzyywsmwgaignexanxvl",          # <--- æ¢æˆä½ çš„ Key
#     base_url="https://api.siliconflow.cn/v1"  # <--- æ¢æˆä½ çš„ Base URL
# )

# # --- 2. å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼šæŠŠæ–‡å­—å˜æˆæ•°å­— ---
# def get_embedding(text):
#     try:
#         # è¿™é‡Œçš„æ¥å£æ˜¯ client.embeddings (ä¸æ˜¯ chat.completions)
#         response = client.embeddings.create(
#             input=text,
#             model=EMBEDDING_MODEL
#         )
#         # æ‹¿åˆ°é‚£ä¸€ä¸²é•¿é•¿çš„æ•°å­—åˆ—è¡¨
#         return response.data[0].embedding
#     except Exception as e:
#         print(f"âŒ å‡ºé”™å•¦ï¼š{e}")
#         return None

# # --- 3. å®šä¹‰ä½™å¼¦ç›¸ä¼¼åº¦å…¬å¼ (Cosine Similarity) ---
# # è¿™æ˜¯é«˜ä¸­æ•°å­¦ï¼šè®¡ç®—ä¸¤ä¸ªå‘é‡å¤¹è§’çš„ä½™å¼¦å€¼ã€‚
# # å€¼è¶Šæ¥è¿‘ 1ï¼Œè¯´æ˜ä¸¤ä¸ªå‘é‡æ–¹å‘è¶Šä¸€è‡´ï¼ˆè¶Šç›¸ä¼¼ï¼‰ã€‚
# def cosine_similarity(v1, v2):
#     return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))

# # --- 4. å®éªŒå¼€å§‹ï¼---
# target_sentence = "æˆ‘çˆ±åƒè‹¹æœ"
# comparison_words = ["æ°´æœ", "æ‰‹æœº", "å¡è½¦", "å–œæ¬¢", "è®¨åŒ"]

# print(f"ğŸ¯ ç›®æ ‡å¥å­ï¼šã€{target_sentence}ã€‘\n")
# print("æ­£åœ¨æŠŠæ–‡å­—å˜æˆæ•°å­—å‘é‡... (å¯èƒ½éœ€è¦å‡ ç§’é’Ÿ)")

# # 1. å…ˆæŠŠç›®æ ‡å¥å­å˜æˆå‘é‡
# v_target = get_embedding(target_sentence)

# if v_target:
#     # 2. éå†å¯¹æ¯”è¯ï¼Œçœ‹çœ‹è°çš„å¾—åˆ†é«˜
#     for word in comparison_words:
#         v_word = get_embedding(word)
#         if v_word:
#             score = cosine_similarity(v_target, v_word)
#             print(f" - å’Œã€{word}ã€‘çš„ç›¸ä¼¼åº¦ï¼š{score:.4f}")
import chromadb
from chromadb.utils import embedding_functions

# --- 1. åˆå§‹åŒ–æ•°æ®åº“ ---
# æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªåªæœ‰å†…å­˜çš„æ•°æ®åº“ï¼ˆç¨‹åºä¸€å…³å°±æ¸…ç©ºï¼‰ï¼Œæ–¹ä¾¿æµ‹è¯•
print("ğŸ“š æ­£åœ¨åˆå§‹åŒ– ChromaDB æ•°æ®åº“...")
chroma_client = chromadb.Client()

# åˆ›å»ºä¸€ä¸ªé›†åˆ (Collection)ï¼Œä½ å¯ä»¥æŠŠå®ƒç†è§£ä¸ºä¸€å¼ â€œè¡¨â€
# åå­—éšä¾¿èµ·ï¼Œæ¯”å¦‚å« "my_knowledge_base"
collection = chroma_client.create_collection(name="demo_collection")

# --- 2. å‡†å¤‡å…¥åº“çš„æ•°æ® ---
documents = [
    "è‹¹æœå«æœ‰ä¸°å¯Œçš„ç»´ç”Ÿç´ Cï¼Œæœ‰åŠ©äºå¢å¼ºå…ç–«åŠ›ã€‚",
    "ä¹”å¸ƒæ–¯åœ¨2007å¹´å‘å¸ƒäº†ç¬¬ä¸€ä»£è‹¹æœæ‰‹æœºã€‚",
    "å¡è½¦å¸æœºé€šå¸¸éœ€è¦åœ¨è¿™ä¸ªåŠ æ²¹ç«™ä¼‘æ¯ã€‚",
    "æ·±åº¦æ±‚ç´¢ (DeepSeek) æ˜¯ä¸­å›½æœ€å¼ºçš„å¤§æ¨¡å‹ä¹‹ä¸€ã€‚",
    "æˆ‘å–œæ¬¢åƒé¦™è•‰å’Œè¥¿ç“œã€‚"
]

# ç»™æ¯æ¡æ•°æ®ä¸€ä¸ªèº«ä»½è¯å· (ID)
ids = ["doc1", "doc2", "doc3", "doc4", "doc5"]

# --- 3. å­˜å…¥æ•°æ®åº“ (è‡ªåŠ¨å‘é‡åŒ–ï¼) ---
# âš ï¸ ChromaDB è‡ªå¸¦äº†ä¸€ä¸ªç®€å•çš„ Embedding æ¨¡å‹ (all-MiniLM-L6-v2)
# å®ƒä¼šè‡ªåŠ¨ä¸‹è½½å¹¶è¿è¡Œï¼Œä½ ç”šè‡³ä¸éœ€è¦é… API Keyï¼(è™½ç„¶åªæ”¯æŒè‹±æ–‡æ¯”è¾ƒå¥½ï¼Œä½†ç®€å•ä¸­æ–‡ä¹Ÿèƒ½å‡‘åˆ)
print("ğŸ“¥ æ­£åœ¨æŠŠæ•°æ®å­˜å…¥æ•°æ®åº“ (Chroma ä¼šè‡ªåŠ¨æŠŠå®ƒä»¬å˜æˆå‘é‡)...")
collection.add(
    documents=documents,
    ids=ids
)

# --- 4. æ¨¡æ‹Ÿç”¨æˆ·æœç´¢ ---
user_query = "æˆ‘æƒ³ä¹°ä¸ªç”µå­äº§å“"

print(f"\nğŸ” ç”¨æˆ·æ­£åœ¨æœï¼šã€{user_query}ã€‘")
print("--------------------------------")

# å»æ•°æ®åº“é‡Œæœï¼Œæ‰¾æœ€ç›¸ä¼¼çš„ 2 æ¡
results = collection.query(
    query_texts=[user_query],
    n_results=2 
)

# --- 5. æ˜¾ç¤ºç»“æœ ---
# Chroma ä¼šè¿”å›ï¼š
# 'documents': æœåˆ°çš„åŸæ–‡
# 'distances': è·ç¦»ï¼ˆè¶Šå°è¶Šç›¸ä¼¼ï¼Œæ³¨æ„è¿™é‡Œä¸æ˜¯ç›¸ä¼¼åº¦ï¼Œæ˜¯è·ç¦»ï¼‰
for i in range(len(results['documents'][0])):
    doc = results['documents'][0][i]
    dist = results['distances'][0][i]
    print(f"âœ… æ‰¾åˆ°ç»“æœ {i+1} (è·ç¦» {dist:.4f}):\n   ğŸ‘‰ {doc}")